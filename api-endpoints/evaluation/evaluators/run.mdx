---
title: "Run Evaluator"
description: "Execute an evaluator for testing purposes"
---

# Run Evaluator

**POST** `/api/evaluators/{evaluator_id}/run/`

Executes an evaluator against provided input/output data for testing purposes. This endpoint allows you to test your evaluator configuration before using it in production.

## Authentication

Requires API key authentication. Include your API key in the request headers:

```bash
Authorization: Api-Key YOUR_API_KEY
```

## Path Parameters

| Parameter | Type | Description |
|-----------|------|-------------|
| `evaluator_id` | string | The unique ID of the evaluator to run |

## Request Body

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `llm_input` | string | Yes | The input that was provided to the LLM |
| `llm_output` | string | Yes | The output generated by the LLM |
| `extra_params` | object | No | Additional parameters for evaluation context |

## Examples

### Test LLM Evaluator

<CodeGroup>

```python Python
import requests

evaluator_id = "0f4325f9-55ef-4c20-8abe-376694419947"
url = f"https://api.keywordsai.co/api/evaluators/{evaluator_id}/run/"
headers = {
    "Authorization": "Api-Key YOUR_API_KEY",
    "Content-Type": "application/json"
}

data = {
    "llm_input": "What is the capital of France?",
    "llm_output": "The capital of France is Paris. Paris is located in the north-central part of France and is the country's largest city and political center.",
    "extra_params": {
        "context": "Geography question about European capitals",
        "user_id": "user123"
    }
}

response = requests.post(url, headers=headers, json=data)
print(response.json())
```

```json JSON
{
  "llm_input": "What is the capital of France?",
  "llm_output": "The capital of France is Paris. Paris is located in the north-central part of France and is the country's largest city and political center.",
  "extra_params": {
    "context": "Geography question about European capitals",
    "user_id": "user123"
  }
}
```

</CodeGroup>

### Test Code Evaluator

<CodeGroup>

```python Python
data = {
    "llm_input": "Write a short summary of machine learning.",
    "llm_output": "Machine learning is a subset of artificial intelligence that enables computers to learn and make decisions from data without being explicitly programmed.",
    "extra_params": {
        "topic": "AI/ML",
        "expected_length": "short"
    }
}

response = requests.post(url, headers=headers, json=data)
```

```json JSON
{
  "llm_input": "Write a short summary of machine learning.",
  "llm_output": "Machine learning is a subset of artificial intelligence that enables computers to learn and make decisions from data without being explicitly programmed.",
  "extra_params": {
    "topic": "AI/ML",
    "expected_length": "short"
  }
}
```

</CodeGroup>

### Test Human Evaluator (Simulation)

<CodeGroup>

```python Python
# For human evaluators, this endpoint simulates the evaluation process
data = {
    "llm_input": "Explain quantum computing in simple terms.",
    "llm_output": "Quantum computing uses quantum mechanics principles to process information in ways that classical computers cannot, potentially solving certain problems much faster.",
    "extra_params": {
        "complexity_level": "beginner",
        "target_audience": "general public"
    }
}

response = requests.post(url, headers=headers, json=data)
```

```json JSON
{
  "llm_input": "Explain quantum computing in simple terms.",
  "llm_output": "Quantum computing uses quantum mechanics principles to process information in ways that classical computers cannot, potentially solving certain problems much faster.",
  "extra_params": {
    "complexity_level": "beginner",
    "target_audience": "general public"
  }
}
```

</CodeGroup>

## Response

**Status: 200 OK**

### LLM Evaluator Response

```json
{
  "id": "eval-result-abc123",
  "score": 4.5,
  "evaluation_result": "Excellent response with accurate and comprehensive information. The answer correctly identifies Paris as the capital and provides relevant additional context about its location and significance.",
  "evaluator_id": "0f4325f9-55ef-4c20-8abe-376694419947",
  "created_at": "2025-09-11T09:45:00.000000Z",
  "execution_time_ms": 1250,
  "tokens_used": {
    "input_tokens": 45,
    "output_tokens": 28
  }
}
```

### Code Evaluator Response

```json
{
  "id": "eval-result-def456",
  "score": 3,
  "evaluation_result": "Response length is appropriate for the request",
  "evaluator_id": "code-eval-456",
  "created_at": "2025-09-11T09:45:00.000000Z",
  "execution_time_ms": 45
}
```

### Human Evaluator Response (Simulation)

```json
{
  "id": "eval-result-ghi789",
  "score": null,
  "evaluation_result": "This evaluator requires human input. In production, a human evaluator would review this content and provide a score.",
  "evaluator_id": "human-eval-789",
  "created_at": "2025-09-11T09:45:00.000000Z",
  "execution_time_ms": 10,
  "requires_human_input": true
}
```

## Response Fields

| Field | Type | Description |
|-------|------|-------------|
| `id` | string | Unique identifier for this evaluation result |
| `score` | number\|null | The evaluation score (null for human evaluators awaiting input) |
| `evaluation_result` | string | Detailed evaluation feedback or reasoning |
| `evaluator_id` | string | ID of the evaluator that was run |
| `created_at` | string | ISO timestamp of when the evaluation was performed |
| `execution_time_ms` | number | Time taken to execute the evaluation in milliseconds |
| `tokens_used` | object | Token usage for LLM evaluators (input/output tokens) |
| `requires_human_input` | boolean | Whether this evaluation requires human input (human evaluators only) |

## Use Cases

### Testing Evaluator Configuration

```python
# Test different inputs to validate evaluator behavior
test_cases = [
    {
        "llm_input": "What is 2+2?",
        "llm_output": "2+2 equals 4."
    },
    {
        "llm_input": "What is 2+2?",
        "llm_output": "I don't know."
    },
    {
        "llm_input": "What is 2+2?",
        "llm_output": "The answer to 2+2 is 4. This is a basic arithmetic operation where we add two numbers together."
    }
]

for i, test_case in enumerate(test_cases):
    response = requests.post(url, headers=headers, json=test_case)
    result = response.json()
    print(f"Test {i+1}: Score = {result['score']}, Feedback = {result['evaluation_result']}")
```

### Debugging Evaluator Issues

```python
# Test edge cases to identify potential issues
edge_cases = [
    {
        "llm_input": "",  # Empty input
        "llm_output": "I need more information to help you."
    },
    {
        "llm_input": "Very long question..." * 100,  # Very long input
        "llm_output": "Short answer."
    }
]
```

## Error Responses

### 400 Bad Request

```json
{
  "detail": "llm_input and llm_output are required fields"
}
```

### 401 Unauthorized

```json
{
  "detail": "Your API key is invalid or expired, please check your API key at https://platform.keywordsai.co/platform/api/api-keys"
}
```

### 404 Not Found

```json
{
  "detail": "Not found."
}
```

### 500 Internal Server Error

```json
{
  "detail": "Evaluator execution failed: [specific error message]"
}
```