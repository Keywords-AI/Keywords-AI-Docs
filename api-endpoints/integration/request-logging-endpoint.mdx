---
title: Logging API
api: POST https://api.keywordsai.co/api/request-logs/create/
---

The Async logging endpoint allows you to directly log an LLM inference to Keywords AI, instead of using Keywords AI as a proxy with the [chat completion endpoint](/api-endpoints/proxy-endpoints/chat-completions).

<ResponseField name="model" type="string" required>
Model used for the LLM inference. Default is an empty string. See the list of model
  [here](/integration/supported-models)
</ResponseField>

<ResponseField name="prompt_messages" type="array" required>
An Array of prompt messages. Default is an empty list. 

```python 
"prompt_messages": [
  {
    "role": "user",
    "content": "Hi"
  },
  # optional function call
  {
    "role": "tool",
    "tool_call_id": "your tool call id",
    "content": "...." # tool call content
  }
],
```
</ResponseField>

<ResponseField name="completion_message" type="dict" required>
Completion message in JSON format. Default is an empty dictionary.
```python 
"completion_message": {
    "role": "assistant",
    "content": "Hi, how can I assist you today?"
},
```
</ResponseField>

{/* <ResponseField name="tool_calls" type="array">
  Tools used by the inference model
</ResponseField>

<Accordion>
  <ResponseField name="id" type="string">
  Tool call that this message is responding to.
  </ResponseField>

  <ResponseField name="type" type="string">
  The type of the tool. Currently, only `function` is supported.
  </ResponseField>

  <ResponseField name="function" type="dict">
  </ResponseField>

  <Accordion>
    <ResponseField name="name" type="string">
    </ResponseField>
    <ResponseField name="arguements" type="string">
    </ResponseField>

```python
"function": {
  "name": "get_current_weather", # Function name
  "arguments": "{\n\"location\": \"Boston, MA\"\n}" # Function arguments
}
```
  </Accordion>

</Accordion> */}

<ResponseField name="cost" type="float" default={0}>
Cost of the inference in US dollars.
</ResponseField>

<ResponseField name="completion_tokens" type="integer" >
Number of tokens in the completion. 
</ResponseField>

<ResponseField name="completion_unit_price" type="number">
Pass this parameter in if you want to log your self-host / fine-tuned model.
<Accordion title="Example">
```json
{
"completion_unit_price": 0.0042 // $0.0042 per 1M tokens
}
```
</Accordion>
</ResponseField>

<ResponseField name="customer_params" type="string">
  Parameters related to the customer. Default is an empty dictionary.
  <AccordionGroup>
    <Accordion title="Properties">
      <ResponseField name="customer_identifier" type="string" required>
        An identifier for the customer that invoked this LLM inference, helps with
        visualizing user activities. Default is an empty string.  See the [details of customer identifier here.](/features/generation/customer-identifier)
      </ResponseField>
      <ResponseField name="name" type="string" >
        Name of the customer. Default is an empty string.
      </ResponseField>
      <ResponseField name="email" type="string" >
        Email of the customer. Default is an empty string.
      </ResponseField>
    </Accordion>
    <Accordion title="Example">
```json
{
      "customer_params": {
        "customer_identifier": "customer_123",
        "name": "Hendrix Liu", //optional
        "email": "hendrix@keywordsai.co" //optional
    }
}
```
    </Accordion>

  </AccordionGroup>
</ResponseField>

<ParamField path="custom_identifier" type="string">
You can use this parameter to send an extra custom tag with your request. This will help you to identify LLM logs faster than `metadata` parameter, because it's indexed. You can see it in Logs with name `Custom ID` field.

<Accordion title="Example">
```json
{
  "custom_identifier": "my_value"
}
```
</Accordion>
</ParamField>

<ResponseField name="error_message" type="text">
Error message if the LLM inference failed. Default is an empty string.
</ResponseField>

<ResponseField name="full_request" type="object">
  The full request object. Default is an empty dictionary. This is optional and it is helpful for logging configurations such as `temperature`, `precence_penalty` etc.
  <Note>`completion_messages`, `tool_calls` will be automatically extracted from full_request</Note>
  ```json
{
"full_request": {
  "temperature": 0.5,
  "top_p": 0.5,
  //... other parameters
},
}

```
</ResponseField>

<ParamField path="frequency_penalty" type="number">
  Specify how much to penalize new tokens based on their existing frequency in
  the text so far. Decreases the model's likelihood of repeating the same line
  verbatim
</ParamField>

<ResponseField name="generation_time" type="float" default={0}>
Total generation time. Generation time = TTFT (Time To First Token) + TPOT (Time Per Output Token) * #tokens. **Do not** confuse this with `ttft`.
</ResponseField>

<ResponseField name="keywordsai_api_controls" type="object">
Use this parameter to control the behavior of the Keywords AI API. Default is an empty dictionary.
<AccordionGroup>
  <Accordion title="Properties">
    <ResponseField name="block" type="boolean" default={true}>
    If false, the server will immediately return a status of whether the logging task is initialized successfully with no log data.
    </ResponseField>
  </Accordion>
  <Accordion title="Example">
```json
{
  "keywordsai_api_controls": {
    "block": true // true or false.
  }
//...other params...
}
```
  </Accordion>
</AccordionGroup>
</ResponseField>

<ResponseField name="metadata" type="dict">
You can add any key-value pair to this metadata field for your reference. 
<Accordion title="Example">
```json
{
  "my_value_key": "my_value"
}
```
</Accordion>
</ResponseField>

<ParamField path="presence_penalty" type="number">
  Specify how much to penalize new tokens based on whether they appear in the
  text so far. Increases the model's likelihood of talking about new topics
</ParamField>

<ResponseField name="prompt_tokens" type="integer">
Number of tokens in the prompt.
</ResponseField>

<ResponseField name="prompt_unit_price" type="number">
Pass this parameter in if you want to log your self-host / fine-tuned model.
<Accordion title="Example">
```json
{
"prompt_unit_price": 0.0042 // $0.0042 per 1M tokens
}
```
</Accordion>
</ResponseField>

<ResponseField name="response_format" type="object">
  The format of the response.
  <Accordion title="Properties">
    <ResponseField name="type" type="string" required>
    The type of the response. Currently, only `text`, `json_schema`, `json_object` are supported.
    </ResponseField>
  </Accordion>
</ResponseField>

<ResponseField name="stream" type="boolean">
  Whether the LLM inference was streamed. Default is false.
</ResponseField>

<ResponseField name="status_code" type="integer" default={200}>
  The status code of the LLM inference. Default is 200 (ok). See supported status codes [here](/error-handling).

</ResponseField>

<ParamField path="stop" type="array[string]">
  Stop sequence
</ParamField>

<ParamField path="temperature" type="number" default={1}>
  Controls randomness in the output in the range of 0-2, higher temperature will
  a more random response.
</ParamField>

<ResponseField name="tools" type="array">
  A list of tools the model may call. Currently, only functions are supported as a tool. 
  <AccordionGroup>
  <Accordion title="Properties">

    <ResponseField name="type" type="string" required>
    The type of the tool. Currently, only `function` is supported.
    </ResponseField>

    <ResponseField name="function" type="object" required>
        <Accordion title="Properties">
          <ResponseField name="name" type="string" required>
          </ResponseField>
          <ResponseField name="description" type="string">
          </ResponseField>
          <ResponseField name="parameters" type="object">
          </ResponseField>
        </Accordion>
    </ResponseField>
</Accordion>

<Accordion title="Example">
  ```python
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_current_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "The city and state, e.g. San Francisco, CA",
            },
            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
          },
          "required": ["location"],
        },
      },
    }
]
```
</Accordion>
</AccordionGroup>
</ResponseField>

<ResponseField name="tool_choice" type="object">
Controls which (if any) tool is called by the model. `none` means the model will not call any tool and instead generates a message. 
<Accordion title="Properties">

  <ResponseField name="type" type="string" required>
  The type of the tool. Currently, only `function` is supported.
  </ResponseField>

  <ResponseField name="function" type="object" required>
  </ResponseField>

<AccordionGroup>
  <Accordion title="Properties">
    <ResponseField name="name" type="string" required>
    </ResponseField>

  </Accordion >
  <Accordion title="Example">
  ```python
    "tool_choice": {
        "type": "function",
        "function": {
            "name": "get_current_weather"
        }
    },
```
</Accordion>
</AccordionGroup>
</Accordion>
</ResponseField>


<ResponseField name="top_p" type="number" default={1}>
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.
</ResponseField>

<ResponseField name="ttft" type="float" default={0.0}>
Time to first token. The time it takes for the model to generate the first token after receiving a request.
</ResponseField>

<ResponseField name="usage" type="object">
Usage details for the LLM inference. Currently, only support Prompt Caching.
  <AccordionGroup>
    <Accordion title="Properties">
      <ResponseField name="prompt_tokens_details" type="object">

      <Accordion title="Properties">
        <ResponseField name="cached_tokens" type="integer">
        Number of tokens in the prompt.
        </ResponseField>
      </Accordion>
      </ResponseField>
      <ResponseField name="cache_creation_prompt_tokens" type="integer">
      This parameter is only applicable for Anthropic models. It represents the number of tokens used to create the cache.
      </ResponseField>
      </Accordion>
  <Accordion title="Example">
  ```json
  {
    "usage": {
        "prompt_tokens_details": {
            "cached_tokens": 10,
        },
        "cache_creation_prompt_tokens": 20, // Anthropic only
    }
  }
  ```
  </Accordion>

  </AccordionGroup>
</ResponseField>

<ResponseField name="warnings" type="string">
  Any warnings that occurred during the LLM inference. You could pass a warning message here. Default is an empty string.
</ResponseField>

{/* <ResponseField name="category" type="string">
Category of the log. Def  ault is an empty string.
</ResponseField> */}

{/* <ResponseField name="cached_response" type="integer">
  Whether the response was cached. Default is 0.
</ResponseField> */}

<RequestExample>

```python Python
import requests

url = "https://api.keywordsai.co/api/request-logs/create/"
headers = {
    "Authorization": "Bearer YOUR_KEYWORDS_AI_API_KEY",
    "Content-Type": "application/json"
}
payload = {
    "model": "gpt-4",
    "prompt_messages": [
        {
          "role": "user",
          "content": "Hi"
        },
        {
          "role": "assistant",
          "content": None,
          "tool_calls": [
            {
              "id": "xxxx",
              "type": "function",
              "function": {
                "name": "get_current_weather", # Function name
                "arguments": "{\n\"location\": \"Boston, MA\"\n}" # Function arguments
              }
            }
          ]
        }, #optional
    ],
    "completion_message": {
        "role": "assistant",
        "content": "Hi, how can I assist you today?"
    },
    "tool_choice": {
        "type": "function",
        "function": {
            "name": "get_current_weather"
        }
    },
    "tools":[
      {
      "type": "function",
      "function": {
        "name": "get_current_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "The city and state, e.g. San Francisco, CA",
            },
            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
          },
          "required": ["location"],
        },
      },
      }
    ],
    "customer_params": {
        "customer_identifier": "customer_123",
        "name": "Hendrix Liu", # optional
        "email": "hendrix@keywordsai.co" # optional
    },
    "prompt_tokens": 8,
    "completion_tokens": 16,
    "cost": 0.00042,
    "latency": 0.0,
    "timestamp": "2024-04-15T08:30:37.721313Z",
    "time_to_first_token": 0.0,
    "metadata": {},
    "stream": False,
    "status_code": 200,
    "warnings": "",
    "error_message": "",
    "type":"text", # "json_schema", "json_object"
}
response = requests.request("POST", url, headers=headers, json=payload)

```
```typescript TypeScript
const url = 'https://api.keywordsai.co/api/request-logs/create/';
const headers = {
    'Authorization': 'Bearer YOUR_KEYWORDS_AI_API_KEY',
    'Content-Type': 'application/json'
};

const payload = {
    model: 'gpt-4',
    prompt_messages: [
      {
        role: 'user',
        content: 'Hi'
      },
      {
        role: 'assistant',
        content: null,
        tool_calls: [
          {
            id: 'xxxx',
            type: 'function',
            function: {
              name: 'get_current_weather',
              arguments: '{"location": "Boston, MA"}'
            }
          }
        ]
      }
    ],
    completion_message: {
        role: 'assistant',
        content: 'Hi, how can I assist you today?'
    },   
    tool_choice: {
        type: 'function',
        function: {
            name: 'get_current_weather'
        }
    },
    tools: [
        {
            type: 'function',
            function: {
                name: 'get_current_weather',
                description: 'Get the current weather in a given location',
                parameters: {
                    type: 'object',
                    properties: {
                        location: {
                            type: 'string',
                            description: 'The city and state, e.g. San Francisco, CA'
                        },
                        unit: { type: 'string', enum: ['celsius', 'fahrenheit'] }
                    },
                    required: ['location']
                }
            }
        }
    ],
    customer_params: {
        customer_identifier: "customer_123",
        name: "Hendrix Liu",  // optional
        email: "hendrix@keywordsai.co" // optional
    },
    prompt_tokens: 8,
    completion_tokens: 16,
    cost: 0.00042,
    generation_time: 0.0,
    timestamp: '2024-04-15T08:30:37.721313Z',
    ttft: 0.0,
    metadata: {},
    stream: false,
    status_code: 200,
    warnings: '',
    error_message: '',
    type:"text", // "json_schema", "json_object"
};

fetch(url, {
    method: 'POST',
    headers: headers,
    body: JSON.stringify(payload)
})
.then(response => response.json())
.then(data => {
    console.log(data);
})
```
```bash cURL
curl -X POST "https://api.keywordsai.co/api/request-logs/create/" \
-H "Content-Type: application/json" \
-H "Authorization: Bearer {YOUR_KEYWORDSAI_API_KEY}" \
-d '{
    "model": "gpt-4",
    "prompt_messages": [
        {
          "role": "user",
          "content": "Hi"
        },
        {
          "role": "assistant",
          "content": null,
          "tool_calls": [
            {
              "id": "xxxx",
              "type": "function",
              "function": {
                "name": "get_current_weather",
                "arguments": "{\n\"location\": \"Boston, MA\"\n}" 
              }
            }
          ]
        }
    ],
    "completion_message": {
        "role": "assistant",
        "content": "Hi, how can I assist you today?"
    },
    "tool_choice": {
        "type": "function",
        "function": {
            "name": "get_current_weather"
        }
    },
    "tools":[
      {
        "type": "function",
        "function": {
          "name": "get_current_weather",
          "description": "Get the current weather in a given location",
          "parameters": {
            "type": "object",
            "properties": {
              "location": {
                "type": "string",
                "description": "The city and state, e.g. San Francisco, CA"
              },
              "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
            },
            "required": ["location"]
          }
        }
      }
    ],
    "prompt_tokens": 8,
    "completion_tokens": 16,
    "cost": 0.00042,
    "generation_time": 0.0,
    "timestamp": "2024-04-15T08:30:37.721313Z",
    "ttft": 0.0,
    "metadata": {},
    "stream": false,
    "status_code": 200,
    "warnings": "",
    "error_message": "",
    "customer_params": {
        "customer_identifier": "customer_123",
        "name": "Hendrix Liu", 
        "email": "hendrix@keywordsai.co" 
    },
    "type":"text",
}'
```
</RequestExample>
<ResponseExample>
</ResponseExample>