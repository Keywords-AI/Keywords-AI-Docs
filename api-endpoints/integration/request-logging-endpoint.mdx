---
title: Log ingestion
api: POST https://api.keywordsai.co/api/request-logs/create/
---

This guide shows you how to log LLM requests to Keywords AI using the structured 3-layer approach for comprehensive LLM logging and monitoring.

## Parameters

These are the essential parameters needed for basic LLM request logging.

### Core required fields

<ParamField body="model" type="string" required>
The LLM model used for the inference. See the list of supported models [here](/integration/supported-models).
</ParamField>

<ParamField body="prompt_messages" type="array" required>
An array of prompt messages sent to the model.

<AccordionGroup>
<Accordion title="Properties">
<ParamField body="role" type="string" required>
The role of the message. Could be `system`, `developer`, `user`, `assistant`, `tool`.
</ParamField>

<ParamField body="content" type="string" required>
The content of the message.
</ParamField>

<ParamField body="tool_call_id" type="string">
The tool call id for tool messages.
</ParamField>
</Accordion>

<Accordion title="Example">
```python
"prompt_messages": [
    {
        "role": "system",
        "content": "You are a helpful assistant."
    },
    {
        "role": "user", 
        "content": "What is machine learning?"
    },
    # optional tool call
    {
        "role": "tool",
        "tool_call_id": "your tool call id",
        "content": "...." # tool call content
    }
]
```
</Accordion>
</AccordionGroup>
</ParamField>

<ParamField body="completion_message" type="object">
The model's response message in JSON format.

<Accordion title="Example">
```python
"completion_message": {
    "role": "assistant",
    "content": "Machine learning is a subset of artificial intelligence..."
}
```
</Accordion>
</ParamField>

### Telemetry

Performance metrics and cost tracking for monitoring LLM efficiency.

<ParamField body="prompt_tokens" type="integer">
Number of tokens in the prompt.
</ParamField>

<ParamField body="completion_tokens" type="integer">
Number of tokens in the completion.
</ParamField>

<ParamField body="cost" type="float" default={0}>
Cost of the inference in US dollars.
</ParamField>

<ParamField body="generation_time" type="float" default={0}>
Total generation time. Generation time = TTFT (Time To First Token) + TPOT (Time Per Output Token) * #tokens. **Do not** confuse this with `ttft`.

<Note>
The unit of generation time is seconds.
</Note>
</ParamField>

<ParamField body="ttft" type="float" default={0.0}>
Time to first token. The time it takes for the model to generate the first token after receiving a request.

<Note>
The unit of ttft is seconds.
</Note>
</ParamField>

### Metadata

Custom tracking and identification parameters for advanced analytics and filtering.

<ParamField body="metadata" type="dict">
You can add any key-value pair to this metadata field for your reference.

<Accordion title="Example">
```json
{
  "metadata": {
    "language": "en",
    "environment": "production",
    "version": "v1.0.0",
    "feature": "chat_support"
  }
}
```
</Accordion>
</ParamField>

<ParamField body="customer_params" type="object">
Parameters related to the customer.

<AccordionGroup>
<Accordion title="Properties">
<ParamField body="customer_identifier" type="string" required>
An identifier for the customer that invoked this LLM inference, helps with visualizing user activities. See the [details of customer identifier here](/features/generation/customer-identifier).
</ParamField>

<ParamField body="name" type="string">
Name of the customer.
</ParamField>

<ParamField body="email" type="string">
Email of the customer.
</ParamField>
</Accordion>

<Accordion title="Example">
```json
{
  "customer_params": {
    "customer_identifier": "customer_123",
    "name": "John Doe",
    "email": "john.doe@example.com"
  }
}
```
</Accordion>
</AccordionGroup>
</ParamField>

<ParamField body="group_identifier" type="string">
Group identifier. Use group identifier to group logs together.
</ParamField>

<ParamField body="thread_identifier" type="string">
A unique identifier for the thread.
</ParamField>

<ParamField body="custom_identifier" type="string">
Same functionality as `metadata`, but it's faster to query since it's indexed.

<Accordion title="Example">
```json
{
  "custom_identifier": "my_value"
}
```
</Accordion>
</ParamField>

## Advanced Parameters

### Tool Calls and Function Calling

<ParamField body="tools" type="array">
A list of tools the model may call. Currently, only functions are supported as a tool.

<AccordionGroup>
<Accordion title="Properties">
<ParamField body="type" type="string" required>
The type of the tool. Currently, only `function` is supported.
</ParamField>

<ParamField body="function" type="object" required>
<Accordion title="Properties">
<ParamField body="name" type="string" required>
The name of the function.
</ParamField>

<ParamField body="description" type="string">
A description of what the function does.
</ParamField>

<ParamField body="parameters" type="object">
The parameters the function accepts.
</ParamField>
</Accordion>
</ParamField>
</Accordion>

<Accordion title="Example">
```python
"tools": [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    },
                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                },
                "required": ["location"],
            },
        },
    }
]
```
</Accordion>
</AccordionGroup>
</ParamField>

<ParamField body="tool_choice" type="object">
Controls which (if any) tool is called by the model. `none` means the model will not call any tool and instead generates a message.

<AccordionGroup>
<Accordion title="Properties">
<ParamField body="type" type="string" required>
The type of the tool. Currently, only `function` is supported.
</ParamField>

<ParamField body="function" type="object" required>
<Accordion title="Properties">
<ParamField body="name" type="string" required>
The name of the function to call.
</ParamField>
</Accordion>
</ParamField>
</Accordion>

<Accordion title="Example">
```python
"tool_choice": {
    "type": "function",
    "function": {
        "name": "get_current_weather"
    }
}
```
</Accordion>
</AccordionGroup>
</ParamField>

### Response Configuration

<ParamField body="response_format" type="object">
Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema.

<Accordion title="Possible types">
<ParamField body="Text" type="Object">
Default response format. Used to generate text responses.
<Accordion title="Properties">
<ParamField body="type" type="string" required>
The type of response format being defined. Always `text`.
</ParamField>
</Accordion>
</ParamField>

<ParamField body="JSON Schema" type="Object">
JSON Schema response format. Used to generate structured JSON responses.
<Accordion title="Properties">
<ParamField body="type" type="string" required>
The type of response format being defined. Always `json_schema`.
</ParamField>

<ParamField body="json_schema" type="object" required>
Structured Outputs configuration options, including a JSON Schema.
</ParamField>
</Accordion>
</ParamField>

<ParamField body="JSON Object" type="Object">
JSON object response format. An older method of generating JSON responses.
<Accordion title="Properties">
<ParamField body="type" type="string" required>
The type of response format being defined. Always `json_object`.
</ParamField>
</Accordion>
</ParamField>
</Accordion>
</ParamField>

### Model Configuration

<ParamField body="temperature" type="number" default={1}>
Controls randomness in the output in the range of 0-2, higher temperature will result in more random responses.
</ParamField>

<ParamField body="top_p" type="number" default={1}>
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.
</ParamField>

<ParamField body="frequency_penalty" type="number">
Penalizes new tokens based on their frequency in the text so far. Decreases the model's likelihood of repeating the same line verbatim.
</ParamField>

<ParamField body="presence_penalty" type="number">
Penalizes new tokens based on whether they appear in the text so far. Increases the model's likelihood of talking about new topics.
</ParamField>

<ParamField body="stop" type="array[string]">
Stop sequences where the API will stop generating further tokens.
</ParamField>

### Error Handling and Status

<ParamField body="status_code" type="integer" default={200}>
The status code of the LLM inference. Default is 200 (ok). See supported status codes [here](/error-handling).

<Accordion title="Supported status codes">
We support all status codes that are valid HTTP status codes.
```200,201,204,301,304,400, 401,402,403,404,405,415,422,429,500,502,503,504``` etc.
</Accordion>
</ParamField>

<ParamField body="error_message" type="text">
Error message if the LLM inference failed. Default is an empty string.
</ParamField>

<ParamField body="warnings" type="string">
Any warnings that occurred during the LLM inference. You could pass a warning message here. Default is an empty string.
</ParamField>

### Additional Configuration

<ParamField body="stream" type="boolean">
Whether the LLM inference was streamed. Default is false.
</ParamField>

<ParamField body="is_custom_prompt" type="boolean" default={false}>
Whether the prompt is a custom prompt. Default is `False`.
</ParamField>

<ParamField body="prompt_id" type="string">
ID of the prompt. If you want to log a custom prompt ID, you need to pass `is_custom_prompt` as `True`. Otherwise, use the Prompt ID in [Prompts](/features/prompt/deploy-a-prompt#1-find-the-prompt-id).
</ParamField>

<ParamField body="prompt_name" type="string">
Name of the prompt.
</ParamField>

<ParamField body="full_request" type="object">
The full request object. Default is an empty dictionary. This is optional and it is helpful for logging configurations such as `temperature`, `presence_penalty` etc.

<Note>`completion_messages`, `tool_calls` will be automatically extracted from full_request</Note>

```json
{
    "full_request": {
        "temperature": 0.5,
        "top_p": 0.5,
        //... other parameters
    }
}
```
</ParamField>

<ParamField body="keywordsai_api_controls" type="object">
Use this parameter to control the behavior of the Keywords AI API. Default is an empty dictionary.

<AccordionGroup>
<Accordion title="Properties">
<ParamField body="block" type="boolean" default={true}>
If false, the server will immediately return a status of whether the logging task is initialized successfully with no log data.
</ParamField>
</Accordion>

<Accordion title="Example">
```json
{
  "keywordsai_api_controls": {
    "block": true // true or false.
  }
//...other params...
}
```
</Accordion>
</AccordionGroup>
</ParamField>

### Pricing Configuration

<ParamField body="prompt_unit_price" type="number">
Pass this parameter in if you want to log your self-host / fine-tuned model.

<Accordion title="Example">
```json
{
"prompt_unit_price": 0.0042 // $0.0042 per 1M tokens
}
```
</Accordion>
</ParamField>

<ParamField body="completion_unit_price" type="number">
Pass this parameter in if you want to log your self-host / fine-tuned model.

<Accordion title="Example">
```json
{
"completion_unit_price": 0.0042 // $0.0042 per 1M tokens
}
```
</Accordion>
</ParamField>

### Usage Details

<ParamField body="usage" type="object">
Usage details for the LLM inference. Currently, only support Prompt Caching.

<AccordionGroup>
<Accordion title="Properties">
<ParamField body="prompt_tokens_details" type="object">
<Accordion title="Properties">
<ParamField body="cached_tokens" type="integer">
Number of tokens in the prompt.
</ParamField>
</Accordion>
</ParamField>

<ParamField body="cache_creation_prompt_tokens" type="integer">
This parameter is only applicable for Anthropic models. It represents the number of tokens used to create the cache.
</ParamField>
</Accordion>

<Accordion title="Example">
```json
{
  "usage": {
      "prompt_tokens_details": {
          "cached_tokens": 10,
      },
      "cache_creation_prompt_tokens": 20, // Anthropic only
  }
}
```
</Accordion>
</AccordionGroup>
</ParamField>

<ParamField body="positive_feedback" type="boolean">
Whether the user liked the output. `True` means the user liked the output.
</ParamField>


<RequestExample>
  ```python Python
  import requests

  url = "https://api.keywordsai.co/api/request-logs/create/"
  headers = {
      "Authorization": "Bearer YOUR_KEYWORDS_AI_API_KEY",
      "Content-Type": "application/json"
  }
  payload = {
      "model": "gpt-4",
      "prompt_messages": [
          {
            "role": "user",
            "content": "Hi"
          },
          {
            "role": "assistant",
            "content": None,
            "tool_calls": [
              {
                "id": "xxxx",
                "type": "function",
                "function": {
                  "name": "get_current_weather", # Function name
                  "arguments": "{\n\"location\": \"Boston, MA\"\n}" # Function arguments
                }
              }
            ]
          }, #optional
      ],
      "completion_message": {
          "role": "assistant",
          "content": "Hi, how can I assist you today?"
      },
      "tool_choice": {
          "type": "function",
          "function": {
              "name": "get_current_weather"
          }
      },
      "tools":[
        {
        "type": "function",
        "function": {
          "name": "get_current_weather",
          "description": "Get the current weather in a given location",
          "parameters": {
            "type": "object",
            "properties": {
              "location": {
                "type": "string",
                "description": "The city and state, e.g. San Francisco, CA",
              },
              "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
            },
            "required": ["location"],
          },
        },
        }
      ],
      "customer_params": {
          "customer_identifier": "customer_123",
          "name": "Hendrix Liu", # optional
          "email": "hendrix@keywordsai.co" # optional
      },
      "prompt_tokens": 8,
      "completion_tokens": 16,
      "cost": 0.00042,
      "latency": 0.0,
      "timestamp": "2024-04-15T08:30:37.721313Z",
      "time_to_first_token": 0.0,
      "metadata": {},
      "stream": False,
      "status_code": 200,
      "warnings": "",
      "error_message": "",
      "type":"text", # "json_schema", "json_object"
  }
  response = requests.request("POST", url, headers=headers, json=payload)

  ```

  ```typescript TypeScript
  const url = 'https://api.keywordsai.co/api/request-logs/create/';
  const headers = {
      'Authorization': 'Bearer YOUR_KEYWORDS_AI_API_KEY',
      'Content-Type': 'application/json'
  };

  const payload = {
      model: 'gpt-4',
      prompt_messages: [
        {
          role: 'user',
          content: 'Hi'
        },
        {
          role: 'assistant',
          content: null,
          tool_calls: [
            {
              id: 'xxxx',
              type: 'function',
              function: {
                name: 'get_current_weather',
                arguments: '{"location": "Boston, MA"}'
              }
            }
          ]
        }
      ],
      completion_message: {
          role: 'assistant',
          content: 'Hi, how can I assist you today?'
      },   
      tool_choice: {
          type: 'function',
          function: {
              name: 'get_current_weather'
          }
      },
      tools: [
          {
              type: 'function',
              function: {
                  name: 'get_current_weather',
                  description: 'Get the current weather in a given location',
                  parameters: {
                      type: 'object',
                      properties: {
                          location: {
                              type: 'string',
                              description: 'The city and state, e.g. San Francisco, CA'
                          },
                          unit: { type: 'string', enum: ['celsius', 'fahrenheit'] }
                      },
                      required: ['location']
                  }
              }
          }
      ],
      customer_params: {
          customer_identifier: "customer_123",
          name: "Hendrix Liu",  // optional
          email: "hendrix@keywordsai.co" // optional
      },
      prompt_tokens: 8,
      completion_tokens: 16,
      cost: 0.00042,
      generation_time: 0.0,
      timestamp: '2024-04-15T08:30:37.721313Z',
      ttft: 0.0,
      metadata: {},
      stream: false,
      status_code: 200,
      warnings: '',
      error_message: '',
      type:"text", // "json_schema", "json_object"
  };

  fetch(url, {
      method: 'POST',
      headers: headers,
      body: JSON.stringify(payload)
  })
  .then(response => response.json())
  .then(data => {
      console.log(data);
  })
  ```

  ```bash cURL
  curl -X POST "https://api.keywordsai.co/api/request-logs/create/" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer {YOUR_KEYWORDSAI_API_KEY}" \
  -d '{
      "model": "gpt-4",
      "prompt_messages": [
          {
            "role": "user",
            "content": "Hi"
          },
          {
            "role": "assistant",
            "content": null,
            "tool_calls": [
              {
                "id": "xxxx",
                "type": "function",
                "function": {
                  "name": "get_current_weather",
                  "arguments": "{\n\"location\": \"Boston, MA\"\n}" 
                }
              }
            ]
          }
      ],
      "completion_message": {
          "role": "assistant",
          "content": "Hi, how can I assist you today?"
      },
      "tool_choice": {
          "type": "function",
          "function": {
              "name": "get_current_weather"
          }
      },
      "tools":[
        {
          "type": "function",
          "function": {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
              "type": "object",
              "properties": {
                "location": {
                  "type": "string",
                  "description": "The city and state, e.g. San Francisco, CA"
                },
                "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
              },
              "required": ["location"]
            }
          }
        }
      ],
      "prompt_tokens": 8,
      "completion_tokens": 16,
      "cost": 0.00042,
      "generation_time": 0.0,
      "timestamp": "2024-04-15T08:30:37.721313Z",
      "ttft": 0.0,
      "metadata": {},
      "stream": false,
      "status_code": 200,
      "warnings": "",
      "error_message": "",
      "customer_params": {
          "customer_identifier": "customer_123",
          "name": "Hendrix Liu", 
          "email": "hendrix@keywordsai.co" 
      },
      "type":"text",
  }'
  ```
</RequestExample>