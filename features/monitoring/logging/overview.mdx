---
title: "Overview"
description: "A guide to log, monitor, and improve LLM outputs."
---

{/* ## Features
<Tabs>

<Tab title="Logging">

</Tab>

</Tabs> */}

## What is an LLM log?

An LLM log is a record of an LLM request. It includes the prompt, the response, and the metadata associated with the request. 

In Keywords AI, you can see every LLM log's metrics like `Messages`, `Model`, `Provider`, `User`, `API key`, `Prompt`, `Response`, `Cost`, `Duration`, `Status`, and `Timestamp`.

## You will love it when you want to:
- See the prompt and response of an LLM log.
- Debug an LLM error.
- Target a specific LLM log.
- See metadata of each LLM log.


## Quick start
To enable logging, you can use the Logging API,Tracing API, or the LLM proxy to log each LLM request.

<CardGroup>
<Card title="Logging API" href="/features/monitoring/get-started/logging-api">

</Card>

<Card title="Tracing API" href="/features/monitoring/get-started/tracing-api">

</Card>

<Card title="LLM proxy" href="/features/monitoring/get-started/llm-proxy">

</Card>
</CardGroup>
