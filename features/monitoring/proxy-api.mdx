---
title: "LLM proxy"
description: "Keywords AI LLM proxy supports you call 250+ LLMs using the same input/output format."
og:title: 'LLM proxy'
---

## How to use Keywords AI AI gateway

### 1. Get your Keywords AI LLM proxy

After you create an account on [Keywords AI](https://platform.keywordsai.co), you can get your API key from the [API keys page](https://platform.keywordsai.co/platform/api/api-keys).

<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/get-started/api-keys.png" alt="Create API key placeholder" />

{/* - Pick an expiry date (optional, default is never expired) */}
{/* - Choose the models you want the router to route between (pick at least one) */}
{/* - Pick a rate limit (option, default as the maximum rate limit of your plan, see [rate limit](/guides/limits#rate-limits)) */}
{/* - Pick a spending limit (optional) */}

The API key will show up only once, <strong>Be careful and save it somewhere safe!</strong>

{/* <Card icon="link" href="/api-usage/api-keys" title="API Key Concepts">
  Learn More about Keywords AI API keys here
</Card> */}

### 2. Integrate AI gateway into your codebase
Keywords AI offers various integration options, including: mainstream LLM frameworks and REST APIs.

<Tabs>
<Tab title="Standard API call">
If you are not using any LLM frameworks, you can use the standard API call to connect 250+ LLMs.
<CodeGroup>
```python Python
import requests
def demo_call(input, 
              model="gpt-4o-mini",
              token="YOUR_KEYWORDS_AI_API_KEY"
              ):
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {token}',
    }

    data = {
        'model': model,
        'messages': [{'role': 'user', 'content': input}],
    }

    response = requests.post('https://api.keywordsai.co/api/chat/completions', headers=headers, json=data)
    return response

messages = "Say 'Hello World'"
print(demo_call(messages).json())
```

```TypeScript TypeScript
fetch('https://api.keywordsai.co/api/chat/completions', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer YOUR_KEYWORDS_AI_API_KEY'
  },
    body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [{role: 'user', content: "Say 'Hello World'"}]
    })
})
.then(response => response.json())
.then(data => console.log(data));
```

```bash Bash
curl -X POST "https://api.keywordsai.co/chat/completions" 
-H "Content-Type: application/json" 
-H "Authorization: Bearer Your_KeywordsAI_API_Key" 
-d "{
  "model": "gpt-4o-mini",
  "messages": [{"role": "user", "content": "Hello"}],
}"
```

```PHP PHP
<?php
  $ch = curl_init();
    
  curl_setopt($ch, CURLOPT_URL, "https://api.keywordsai.co/chat/completions");
  curl_setopt($ch, CURLOPT_POST, 1);
  curl_setopt($ch, CURLOPT_HTTPHEADER, array(
    "Content-Type: application/json",
    "Authorization: Bearer Your_KeywordsAI_API_Key",
  ));
  curl_setopt($ch, CURLOPT_POSTFIELDS, json_encode(array(
    "model" => "gpt-4o-mini",
    "messages" => array(["role" => "user", "content" => "Hello"]),
  )));
    
  $response = curl_exec($ch);
  curl_close($ch);
?>
```

```Go Go
package main
import (
  "bytes"
  "net/http"
)
    
func main() {
  url := "https://api.keywordsai.co/chat/completions"
  method := "POST"
    
  payload := []byte(`{
    "model" : "gpt-4o-mini",
    "messages": [{"role": "user", "content": "Hello"}],
  }`)
    
  client := &http.Client{}
  req, err := http.NewRequest(method, url, bytes.NewBuffer(payload))
    
  if err != nil {
    panic(err)
  }
    
  req.Header.Add("Content-Type", "application/json")
  req.Header.Add("Authorization", "Bearer Your_KeywordsAI_API_Key")
    
  res, err := client.Do(req)
  defer res.Body.Close()
}
```
</CodeGroup>
</Tab>
<Tab title="OpenAI SDK">
If you are using OpenAI SDK, it's pretty straightforward to integrate AI gateway into your codebase.
* set the `base_url` to `https://api.keywordsai.co/api`
* set the `api_key` to your Keywords AI API key
Go to this page to learn details of OpenAI SDK Integration.
<Card title="OpenAI SDK Integration" href="/integration/development-frameworks/openai-sdk">
</Card>
</Tab>
<Tab title="Other LLM frameworks">
We also support other LLM frameworks, pick the one you are using and follow the instructions.
<CardGroup columns={3}>
<Card title="Anthropic" href="/integration/development-frameworks/anthropic">
</Card>
<Card title="LangChain" href="/integration/development-frameworks/langchain">
</Card>
<Card title="Vercel AI SDK" href="/integration/development-frameworks/vercel">
</Card>
<Card title="LlamaIndex" href="/integration/development-frameworks/llama-index">
</Card>
</CardGroup>
</Tab>
</Tabs>

### 3. Add your credentials to activate AI gateway
For all AI gateway users, you have to add your own credentials to activate AI gateway. We will use your credentials to call LLMs on your behalf. For example, if you want to use OpenAI, you have to add your OpenAI API key to activate AI gateway.

We **won't use your credentials** for any other purposes.

You can go to the [Credentials page](https://platform.keywordsai.co/platform/api/credentials) to add your credentials. 
<img  src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/get-started/credentials.png" alt="Credentials page"/>

<Tip>Learn how to add credentials to a specific provider [here](/integration/own-api-keys).</Tip>

### 4. Parameters
We support all OpenAI parameters. which is the standard format for LLMs. You can check out important [OpenAI parameters in this page](/api-endpoints/integration/chat-completions#openai-parameters). You can also learn more about OpenAI parameters [here](https://platform.openai.com/docs/api-reference/chat).

For **Keywords AI parameters**, you should use them when you want to achieve specific goals. For example, you can use `fallback_models` to specify fallback models when the primary model is down. You can check out all [Keywords AI parameters in this page](/api-endpoints/integration/chat-completions#keywords-ai-parameters).

{/* ### Try Keywords AI with the OpenAI SDK  */}
{/* **Install the OpenAI SDK**

```bash 
pip install openai 
```
<CodeGroup>
```Python Python
from openai import OpenAI


client = OpenAI(
    base_url="https://api.keywordsai.co/api/",
    api_key="YOUR_KEYWORDSAI_API_KEY",
)

response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role":"user", "content":"Tell me a long story"}],
    stream=True,
    extra_body={"customer_identifier": "customer_11"}
)
```

```TypeScript TypeScript
import { OpenAI } from "openai";

const client = new OpenAI({
  baseURL: "https://api.keywordsai.co/api",
  apiKey: process.env.KEYWORDS_AI_API_KEY,
});

const response = await client.chat.completions
  .create({
    messages: [{ role: "user", content: "Say this is a test" }],
    model: "gpt-3.5-turbo",
    // @ts-expect-error
    customer_identifier: "test_openai_chat",
  })
  .asResponse();

console.log(await response.json());

```
</CodeGroup> */}

{/* ### Try Keywords AI with a standard API call



- **URL change**: Modify the API endpoint URL in your code from OpenAIâ€™s URL to the Keywords AI endpoint URL: `https://keywordsai.co/api/chat/completions`.
- **API key**: Replace the OpenAI API key with your Keywords AI API key.
- **Parameters**: See supported parameters in the [API reference](/api-endpoints/proxy-endpoints/chat-completions).

## Response

The results should be printed in the console.

```json
{
  "id": "chatcmpl-8Ygj0WAGNhHBFjatPCefcPeNi12ct",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": { "content": "Hello World", "role": "assistant" }
    }
  ],
  "created": 1703230636,
  "model": "gpt-3.5-turbo",
  "object": "chat.completion",
  "system_fingerprint": null,
  "usage": { "completion_tokens": 2, "prompt_tokens": 12, "total_tokens": 14 },
  "_response_ms": 653.2679999999999
}
``` */}
