---
title: "Set up Traces"
description: "Monitor complex LLM workflows including chains, agents with tools, and advanced prompts in your AI products using Traces."
---

<Note>
Traces is currently in **beta**. Please share any feedback or suggestions.
</Note>

## Set up Traces

<Steps>
<Step title="Install the SDK">
Install the package using your preferred package manager:
<CodeGroup>
```bash pip
pip install keywordsai-tracing
```
```bash poetry
poetry add keywordsai-tracing
```
</CodeGroup>
</Step>

<Step title="Set up Environment Variables">
Get your API key from the [API Keys page](https://platform.keywordsai.co/platform/api/api-keys) in Settings, then configure it in your environment:

```python Python
import os
from keywordsai_tracing.main import KeywordsAITelemetry

os.environ["KEYWORDSAI_API_KEY"] = "YOUR_KEYWORDSAI_API_KEY"
k_tl = KeywordsAITelemetry()
```
</Step>

<Step title="Annotate your workflows">
Use the `@workflow` and `@task` decorators to instrument your code:
```python Python {3, 5}
from keywordsai_tracing.decorators import workflow, task

@workflow(name="my_workflow")
def my_workflow():
    @task(name="my_task")
    def my_task():
        pass
    my_task()
```
</Step>
</Steps>

## Understanding Workflows and Tasks

A workflow is a sequence of tasks that you want to monitor. Each task represents a single unit of work within that workflow.

### Example

Below is an example that demonstrates how to use tasks and workflows. We'll create a workflow that:
1. Generates a joke
2. Translates it to pirate speak
3. Adds a signature

Each operation is implemented as a separate task that can be used independently or as part of the workflow.

```python Python {1,15,25}
@task(name="joke_creation")
def create_joke():
    completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": "Tell me a joke about opentelemetry"}],
        temperature=0.5,
        max_tokens=100,
        frequency_penalty=0.5,
        presence_penalty=0.5,
        stop=["\n"],
        logprobs=True,
    )
    return completion.choices[0].message.content

@task(name="signature_generation")
def generate_signature(joke: str):
    completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": "add a signature to the joke:\n\n" + joke}
        ],
    )
    return completion.choices[0].message.content

@task(name="pirate_joke_translation")
def translate_joke_to_pirate(joke: str):
    completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "user",
                "content": "translate the joke to pirate language:\n\n" + joke,
            }
        ],
    )
    return completion.choices[0].message.content
```

Chain these tasks together in a workflow:

```python Python {1}
@workflow(name="joke_workflow")
def joke_workflow():
    joke = create_joke()
    pirate_joke = translate_joke_to_pirate(joke)
    signature = generate_signature(pirate_joke)
    return signature
```
You can then see the trace in the [Traces](https://platform.keywordsai.co/platform/traces).
<Frame>
<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/traces/tracing-example.png" alt="Traces example" />
</Frame>


_Example adapted from [Traceloop](https://traceloop.com)_