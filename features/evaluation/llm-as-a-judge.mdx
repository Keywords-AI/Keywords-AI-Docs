---
title: LLM-as-a-judge
description: Evaluate your prompts with the help of LLM
icon: "scale-unbalanced"
---
LLM as a judge is a feature that allows you to evaluate your prompts with the help of LLM. You can evaluate your prompts based on various metrics and see the results on the Logs page.
<Note>This is a beta feature. Please do let us know if you encounter any issues. We’ll continuously improve it.</Note>

<Steps>
<Step title="Create an evaluator">
To evaluate your prompts, you should first create a new evaluator on the [Evaluators page](https://platform.keywordsai.co/platform/evaluators).

After you click on the `Create Evaluator` button, you will see the following page. You will then need to define the `evaluator slug` for applying the evaluator in your LLM calls.
<img height="300" noZoom src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/eval-slug.png" />
</Step>

{/* <Step title="Choose a metric">
Choose a metric to evaluate your prompts. We integrted Evaluation framework from [Relari](https://docs.relari.ai/metrics/intro)(Comming soon) and [Ragas](https://docs.ragas.io/en/stable/concepts/metrics/index.html).
<Note>We are adding more metrics. [Let us know](https://discord.com/invite/KEanfAafQQ) if you want to add a specific metric.</Note>
<img height="200" noZoom src="https://keywordsai-static.s3.amazonaws.com/docs/evals-metric.png" />
</Step> */}

<Step title="Configure the evaluator">
Configure the evaluator with the prompt and the customer you want to evaluate. You can also test the evaluator with a sample prompt。
{/* <img height="200" noZoom src="https://keywordsai-static.s3.amazonaws.com/docs/eval-config.png" /> */}
</Step>

<Step title="Pass required params in code">
After you have configured the evaluator, you should pass the required parameters in the code to evaluate the prompt.

For example, you are asking a question about the capital of France, and you have retrieved some context about France and Paris.

You have defined an evaluator with the slug `evaluator-slug1`, and the required fields in the evaluator are `retrieved_contexts`, `expected_response`, `input_text` (default), and `output_text` (default).

By default, input_text will be extracted from messages array and output_text will be extracted from the LLM's response, you DON'T need to specify them in the extra_params.

**Example code:**
```json
{
  "model": "gpt-4o-mini",
  "messages": [
    {
      "role": "user",
      "content": "What is the capital of France?"
    }
  ],
  "evaluation_params": { 
    "evaluators": [{"evaluator_slug":"evaluator-slug1"}],
    "extra_params": {
        "retrieved_contexts": ["the capital of France is Paris", "France is a country in Europe"],
        "expected_response": "Paris"
    },
    "last_n_messages": 3, // We will use the last 3 messages of the `messages` array as the input.
  },
}
```

{/* **Explanation of `extra_params`**

You must pass the `extra_params` based on the metric you choose. For example, if you choose the `Ragas Answer Relevancy` metric, you can find the required parameters are`Question`, `Answer`, and `Contexts`.
<Warning>The `Question` and `Answer` fields are automatically extracted from the conversation log if required by the evaluator, so you don't need to be explicitly provided in extra_params. </Warning>
<img height="200" noZoom src="https://keywordsai-static.s3.amazonaws.com/docs/eval-params.png" /> */}
</Step>
<Step title="See the result">
The evaluator will automatically run on the LLM call and you will be able to see the results in the side panel of the corresponding log.
{/* <img height="200" noZoom src="https://keywordsai-static.s3.amazonaws.com/docs/eval-results.png" /> */}
</Step>
</Steps>

