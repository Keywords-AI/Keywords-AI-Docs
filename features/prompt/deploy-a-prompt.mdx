---
title: "Deploy a prompt"
description: "Deploy a prompt to your codebase."
---

After you create a prompt, you can deploy it to your codebase, and then you can call it through the API.

## 1. Find the Prompt ID
You should first find the Prompt ID of the prompt you want to deploy. You can find the Prompt ID in the Overview panel on the [Prompts page](https://platform.keywordsai.co/platform/prompts).
<Frame>
<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/prompt/prompt-id.png" alt="Prompt ID" />
</Frame>

## 2. Connect the prompt to codebase
Integrate the prompt to the codebase by adding the following code to your codebase.

<Tabs>
<Tab title="OpenAI Python SDK">
```python {13-18}
from openai import OpenAI

client = OpenAI(
  base_url="https://api.keywordsai.co/api/", # switch to the Keywords AI base URL
  api_key="YOUR_API_KEY", # switch to your Keywords AI API key
)

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "user", "content": "Tell me a long story"}
    ],
    extra_body={"prompt": {"prompt_id":"042f5f",
                "variables":{"task_description":"Square a number", "specific_library":"math"},
                "version": "1",
                "override": True,
                }
    }
)
```
<Note>
Since OpenAI forces you to pass the `model` and `messages` fields, you should pass the an `override` field to the `prompt` field, which will override the `model` and `messages` fields and use the prompt you created on Keywords AI.
</Note>
</Tab>
<Tab title="OpenAI TypeScript SDK">
In OpenAI TypeScript SDK, you should add a `// @ts-expect-error` before the `prompt` field.
```typescript {12-18}
import { OpenAI } from "openai";

const client = new OpenAI({
  baseURL: "https://api.keywordsai.co/api",
  apiKey: "YOUR_KEYWORDSAI_API_KEY",
});

const response = await client.chat.completions
  .create({
    messages: [{ role: "user", content: "Say this is a test" }],
    model: "gpt-4o-mini",
    // @ts-expect-error
    prompt: {
      prompt_id: "042f5f",
      variables: { task_description: "Square a number", specific_library: "math" },
      version: "1",
      override: true,
    }
  })
  .asResponse();

console.log(await response.json());
```
<Note>
Since OpenAI forces you to pass the `model` and `messages` fields, you should pass the an `override` field to the `prompt` field, which will override the `model` and `messages` fields and use the prompt you created on Keywords AI.
</Note>
</Tab>
<Tab title="Standard API">
```python LLM proxy {14-17}
import requests
def demo_call(token="YOUR_KEYWORDS_AI_API_KEY"):
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {token}',
    }

    data = {
        'prompt': {
            'prompt_id': '042f5f',
            'variables': {'task_description': 'Square a number', 'specific_library': 'math'},
            'version': '1'
        }
    }

    response = requests.post('https://api.keywordsai.co/api/chat/completions', headers=headers, json=data)
    return response

print(demo_call().json())
```
You don't need to pass the `model` and `messages` fields, since the prompt you created on Keywords AI will be used.
</Tab>
<Tab title="Other SDKs">
We also support adding credentials in other SDKs or languages, please check out our [integration section](/integration/own-api-keys) for more information.
</Tab>
</Tabs>

## 3. Deploy the prompt
Once you have connected the prompt to your codebase, you can deploy the prompt on the platform. You can deploy the prompt by clicking on the `Deploy` button on the [Prompts page](https://platform.keywordsai.co/platform/prompts).
<Frame>
<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/prompt/prompt-deploy.png" alt="Deploy prompt" />
</Frame>

### Override prompt messages in the API
You can override the prompt messages in the API by passing the `override_params` and `override_config` field to the `prompt` field.
You can choose to override the whole prompt messages or append a new message to the prompt messages.

**Example**:
```python {4-5}
request_body = {
    "prompt": {
        "prompt_id": "xxxxxx",
        "override_config": {"messages_override_mode": "append"}, # append or override
        "override_params": {"messages": [{"role": "user", "content": "5"}]},
    }
}
```

In this example, the `override_config` specifies how the new messages should be handled:
- When `messages_override_mode` is set to `"append"`, the new message `{"role": "user", "content": "5"}` will be added to the end of the existing prompt messages
- When set to `"override"`, the new messages will completely replace the original prompt messages

## 4. View the logs with the prompt
You can view the logs with the prompt by clicking a log on the [Logs page](https://platform.keywordsai.co/platform/logs) or filtering the logs with the prompt name.
<Frame>
<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/prompt/prompt-logs.png" alt="View prompt" />
</Frame>



## Optional parameters
<ParamField path="echo" type="boolean" default={true}>
  with echo on, the response body will have an extra field
```json
  "prompt_message": [an array of messages]
```
</ParamField>

<ParamField path="override" type="boolean" default={true}>
Turn on override to use params in `override_params` instead of the params in the prompt.
```json
{
  "override": true,
}

```
</ParamField>

<ParamField path="override_params" type="boolean" default={true}>
You can put any OpenAI chat/completions parameters here to override the prompt's parameters. This will only work if `override` is set to `true`.
```json
{
  "override_params": {
    "temperature": 0.5,
    "max_tokens": 100
  }
}
```
</ParamField>

<ParamField path="override_config" type="object">
This parameter allows you to control how you can override the parameters in the prompt.
<Accordion title="messages_override_mode">

    `append`: append the new messages to the existing messages

    `override`: override the existing messages

</Accordion>
</ParamField>

<Info>Check out [all Keywords AI supported params here](/api-endpoints/integration/chat-completions#keywords-ai-parameters).</Info>

## Troubleshooting

### Enable stream when you're using OpenAI SDK
If you're using OpenAI SDK and want to connect with the prompt you created, you have to specify `stream=True` in the call body.
<CodeGroup>
```python OpenAI SDK Python
from openai import OpenAI

client = OpenAI(
    base_url="https://api.keywordsai.co/api/",
    api_key="YOUR_KEYWORDSAI_API_KEY",
)

response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role":"user", "content":"Tell me a long story"}],
    stream=True,
    extra_body={
      "prompt": {
          "prompt_id": "prompt_id", # paste this from the prompt management page
          "variables": {
            "variable_name": "variable_value"
          },
          "version": 1 # specify which version of the prompt you want to use. e.g. 1 for v1
          # "echo": true //optional parameter
        }
    }
)
```

```typescript OpenAI SDK TS
import { OpenAI } from "openai";

const client = new OpenAI({
  baseURL: "https://api.keywordsai.co/api",
  apiKey: process.env.KEYWORDS_AI_API_KEY,
});

const response = await client.chat.completions
  .create({
    messages: [{ role: "user", content: "Say this is a test" }],
    model: "gpt-3.5-turbo",
    stream: true,
    // @ts-expect-error
    prompt: {
      prompt_id: "prompt_id", // paste this from the prompt management page
      variables: {
        variable_name: "variable_value",
      },
      version: 1 // specify which version of the prompt you want to use. e.g. 1 for v1
      // echo: true //optional parameter
    },
  })
  .asResponse();

console.log(await response.json());
```
</CodeGroup>