---
title: "Quickstart"
og:title: 'Quickstart'
---

Keywords AI offers 2 easy ways to leverage the platform: the async LLM logging API and our AI gateway.

<Columns cols={2}>
  <Card title="LLM logging" icon="clipboard" href="#llm-logging">
    Track your LLM usage and performance with 0 latency impact.
  </Card>
  <Card title="AI gateway" icon="arrows-split-up-and-left" href="#ai-gateway">
    Call 250+ LLMs with a single API and get complete observability.
  </Card>
</Columns>

## Choose Your Integration: Logging, Gateway, or Tracing?
<iframe
  className="w-full aspect-video rounded-xl"
  src="https://www.youtube.com/embed/QGrUM_H3q_k"
  title="LLM logging vs AI gateway vs Agent tracing"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen={true}
></iframe>

{/* <Tip>Want to learn more about the **difference** between the two? [Check out the tutorial video here](https://www.youtube.com/watch?v=QGrUM_H3q_k).</Tip> */}
## LLM logging
Keywords AI provides an **Async Logging API** that allows you to log your LLM requests and responses asynchronously, which offers complete observability of your LLM applications and won't disrupt your application's performance.

### 1. Get API key

Sign in to [Keywords AI platform](https://platform.keywordsai.co), and get the API key from the [API keys page](https://platform.keywordsai.co/platform/api/api-keys).

<Frame>
<img className="block dark:hidden" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/get-started/quickstart/get-api-key-light.jpg" alt="Create API key placeholder" />
<img className="hidden dark:block" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/get-started/quickstart/get-api-key-dark.jpg" alt="Create API key placeholder" />
</Frame>

### 2. Call the Logging API


<CodeGroup>
```python Python {3, 18}
import requests

url = "https://api.keywordsai.co/api/request-logs/create/"
payload = {
    "model": "claude-3-5-sonnet-20240620",
    "prompt_messages": [
        {
            "role": "user",
            "content": "Hi"
        },
    ],
    "completion_message": {
        "role": "assistant",
        "content": "Hi, how can I assist you today?"
    },
}
headers = {
    "Authorization": "Bearer YOUR_KEYWORDS_AI_API_KEY",
    "Content-Type": "application/json"
}

response = requests.request("POST", url, headers=headers, json=payload)
```
```typescript TypeScript {1, 3}
const url = 'https://api.keywordsai.co/api/request-logs/create/';
const headers = {
    'Authorization': 'Bearer YOUR_KEYWORDS_AI_API_KEY',
    'Content-Type': 'application/json'
};

const payload = {
    model: 'claude-3-5-sonnet-20240620',
    prompt_messages: [
        {
            role: "user",
            content: "Hi"
        },
    ],
    completion_message: {
        role: "assistant",
        content: "Hi, how can I assist you today?"
    },
};

fetch(url, {
    method: 'POST',
    headers: headers,
    body: JSON.stringify(payload)
})
.then(response => response.json())
.then(data => {
    console.log(data);
})
```

```bash cURL {1, 3}
curl -X POST "https://api.keywordsai.co/api/request-logs/create/" \
-H "Content-Type: application/json" \
-H "Authorization: Bearer {YOUR_KEYWORDS_AI_API_KEY}" \
-d '{
    "model": "claude-3-5-sonnet-20240620",
    "prompt_messages": [
        {
          "role": "user",
          "content": "Hi"
        }
    ],
    "completion_message": {
        "role": "assistant",
        "content": "Hi, how can I assist you today?"
    },
}'
```
</CodeGroup>

<Card title="LLM observability" icon="clipboard" href="/features/monitoring/overview">
Learn more features of LLM observability.
</Card>
<Card title="Other LLM frameworks" icon="clipboard" href="/integration/own-api-keys">
Learn how to integrate Keywords AI with other LLM frameworks.
</Card>

## AI gateway

An AI gateway is a simple “middleman” between you and Large Language Models (LLMs). It handles things like:

- **Routing**: Sending requests to different models or versions
- **Fallback models**: If the primary model is down, the proxy will route to a fallback model
- **Load balancing**: Distributing requests across multiple models
- **Caching**: Caching responses to improve latency and reduce costs

{/* ```mermaid
  flowchart TD;
    A[Input]-->B[AI gateway];
    B-->C[250+ LLMs];
    B-->D[Model fallback];
    B-->E[Load balancing];
    B-->F[Prompt caching];
    C-->Z[Optimized LLM Output];
    D-->Z[Optimized LLM Output];
    E-->Z[Optimized LLM Output];
    F-->Z[Optimized LLM Output];
``` */}

{/* ## Benefits of AI gateway:
- Call over 250 LLMs using the same format.
- Ensure your LLM applications become more scalable and reliable.
- Manage LLM costs in a single place.
- Mange API keys in a single place without exposing them.

## Considerations:
- May not be suitable for products with strict latency requirements (**50 - 150ms** added).
- May not be ideal for those who do not want to integrate a third-party service into the core of their application. */}

### 1. Get API key

Sign in to [Keywords AI platform](https://platform.keywordsai.co), and get the API key from the [API keys page](https://platform.keywordsai.co/platform/api/api-keys).

<Frame>
<img className="block dark:hidden" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/get-started/quickstart/get-api-key-light.jpg" alt="Create API key placeholder" />
<img className="hidden dark:block" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/get-started/quickstart/get-api-key-dark.jpg" alt="Create API key placeholder" />
</Frame>

{/* - Pick an expiry date (optional, default is never expired) */}
{/* - Choose the models you want the router to route between (pick at least one) */}
{/* - Pick a rate limit (option, default as the maximum rate limit of your plan, see [rate limit](/guides/limits#rate-limits)) */}
{/* - Pick a spending limit (optional) */}

{/* The API key will show up only once, <strong>Be careful and save it somewhere safe!</strong> */}

{/* <Card icon="link" href="/api-usage/api-keys" title="API Key Concepts">
  Learn More about Keywords AI API keys here
</Card> */}
### 2. Add credentials
You have to add your own credentials to activate AI gateway otherwise your LLM calls will cause errors. We will use your credentials to call LLMs on your behalf.

We **won't use your credentials** for any other purposes and no extra charges will be applied.

Go to the [Providers page](https://platform.keywordsai.co/platform/api/providers) to add your credentials. 
<Frame>
<img className="block dark:hidden" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/settings/providers.jpg" alt="Providers page"/>
<img className="hidden dark:block" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/settings/providers-dark.jpg" alt="Providers page"/>
</Frame>

<Tip>Learn how to add credentials to a specific provider [here](/integration/own-api-keys).</Tip>

### 3. Integrate AI gateway
Keywords AI offers various integration options, including: mainstream LLM frameworks and REST APIs.

<Tabs>
<Tab title="OpenAI SDK">
If you are using OpenAI SDK, it's pretty straightforward to integrate AI gateway into your codebase.
* set the `base_url` to `https://api.keywordsai.co/api`
* set the `api_key` to your Keywords AI API key
Go to this page to learn details of OpenAI SDK Integration.

<CodeGroup>
```python Python
from openai import OpenAI

client = OpenAI(
    base_url="https://api.keywordsai.co/api/",
    api_key="YOUR_KEYWORDSAI_API_KEY",
)

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role":"user", "content":"Tell me a long story"}],
)
```
```TypeScript TypeScript
import { OpenAI } from "openai";

const client = new OpenAI({
  baseURL: "https://api.keywordsai.co/api",
  apiKey: "YOUR_KEYWORDS_AI_API_KEY",
});

const response = await client.chat.completions
  .create({
    messages: [{ role: "user", content: "Say this is a test" }],
    model: "gpt-4o-mini",
  })
  .asResponse();

console.log(await response.json());
```
</CodeGroup>

</Tab>

<Tab title="Standard API call">
If you are not using any LLM frameworks, you can use the standard API call to connect 250+ LLMs.
<CodeGroup>
```python Python
import requests
def demo_call(input, 
              model="gpt-4o-mini", # also try "claude-3-5-sonnet-20240620"
              token="YOUR_KEYWORDS_AI_API_KEY"
              ):
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {token}',
    }

    data = {
        'model': model,
        'messages': [{'role': 'user', 'content': input}],
    }

    response = requests.post('https://api.keywordsai.co/api/chat/completions', headers=headers, json=data)
    return response

messages = "Say 'Hello World'"
print(demo_call(messages).json())
```

```TypeScript TypeScript
fetch('https://api.keywordsai.co/api/chat/completions', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer YOUR_KEYWORDS_AI_API_KEY'
  },
    body: JSON.stringify({
        model: 'gpt-4o-mini', // also try "claude-3-5-sonnet-20240620"
        messages: [{role: 'user', content: "Say 'Hello World'"}]
    })
})
.then(response => response.json())
.then(data => console.log(data));
```

```bash Bash
curl -X POST "https://api.keywordsai.co/chat/completions" 
-H "Content-Type: application/json" 
-H "Authorization: Bearer Your_KeywordsAI_API_Key" 
-d "{
  "model": "gpt-4o-mini",
  "messages": [{"role": "user", "content": "Hello"}],
}"
```

```PHP PHP
<?php
  $ch = curl_init();
    
  curl_setopt($ch, CURLOPT_URL, "https://api.keywordsai.co/chat/completions");
  curl_setopt($ch, CURLOPT_POST, 1);
  curl_setopt($ch, CURLOPT_HTTPHEADER, array(
    "Content-Type: application/json",
    "Authorization: Bearer Your_KeywordsAI_API_Key",
  ));
  curl_setopt($ch, CURLOPT_POSTFIELDS, json_encode(array(
    "model" => "gpt-4o-mini",
    "messages" => array(["role" => "user", "content" => "Hello"]),
  )));
    
  $response = curl_exec($ch);
  curl_close($ch);
?>
```

```Go Go
package main
import (
  "bytes"
  "net/http"
)
    
func main() {
  url := "https://api.keywordsai.co/chat/completions"
  method := "POST"
    
  payload := []byte(`{
    "model" : "gpt-4o-mini",
    "messages": [{"role": "user", "content": "Hello"}],
  }`)
    
  client := &http.Client{}
  req, err := http.NewRequest(method, url, bytes.NewBuffer(payload))
    
  if err != nil {
    panic(err)
  }
    
  req.Header.Add("Content-Type", "application/json")
  req.Header.Add("Authorization", "Bearer Your_KeywordsAI_API_Key")
    
  res, err := client.Do(req)
  defer res.Body.Close()
}
```
</CodeGroup>
</Tab>
<Tab title="Other LLM frameworks">
We also support other LLM frameworks, pick the one you are using and follow the instructions.
<CardGroup columns={3}>
<Card title="Anthropic" href="/integration/development-frameworks/anthropic">
</Card>
<Card title="LangChain" href="/integration/development-frameworks/langchain">
</Card>
<Card title="Vercel AI SDK" href="/integration/development-frameworks/vercel">
</Card>
<Card title="LlamaIndex" href="/integration/development-frameworks/llama-index">
</Card>
</CardGroup>
</Tab>
</Tabs>



{/* ### 4. Parameters
We support all OpenAI parameters. which is the standard format for LLMs. You can check out important [OpenAI parameters in this page](/api-endpoints/integration/chat-completions#openai-parameters). You can also learn more about OpenAI parameters [here](https://platform.openai.com/docs/api-reference/chat).

For **Keywords AI parameters**, you should use them when you want to achieve specific goals. For example, you can use `fallback_models` to specify fallback models when the primary model is down. You can check out all [Keywords AI parameters in this page](/api-endpoints/integration/chat-completions#keywords-ai-parameters). */}

<Card title="AI gateway" icon="arrows-split-up-and-left" href="/features/generation/overview">
Learn more about AI gateway.
</Card>
<Card title="Other LLM frameworks" icon="arrows-split-up-and-left" href="/integration/own-api-keys">
Learn how to integrate Keywords AI with other LLM frameworks.
</Card>

{/* ### Try Keywords AI with the OpenAI SDK  */}
{/* **Install the OpenAI SDK**

```bash 
pip install openai 
```
<CodeGroup>
```Python Python
from openai import OpenAI


client = OpenAI(
    base_url="https://api.keywordsai.co/api/",
    api_key="YOUR_KEYWORDSAI_API_KEY",
)

response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role":"user", "content":"Tell me a long story"}],
    stream=True,
    extra_body={"customer_identifier": "customer_11"}
)
```

```TypeScript TypeScript
import { OpenAI } from "openai";

const client = new OpenAI({
  baseURL: "https://api.keywordsai.co/api",
  apiKey: process.env.KEYWORDS_AI_API_KEY,
});

const response = await client.chat.completions
  .create({
    messages: [{ role: "user", content: "Say this is a test" }],
    model: "gpt-3.5-turbo",
    // @ts-expect-error
    customer_identifier: "test_openai_chat",
  })
  .asResponse();

console.log(await response.json());

```
</CodeGroup> */}

{/* ### Try Keywords AI with a standard API call



- **URL change**: Modify the API endpoint URL in your code from OpenAI’s URL to the Keywords AI endpoint URL: `https://keywordsai.co/api/chat/completions`.
- **API key**: Replace the OpenAI API key with your Keywords AI API key.
- **Parameters**: See supported parameters in the [API reference](/api-endpoints/proxy-endpoints/chat-completions).

## Response

The results should be printed in the console.

```json
{
  "id": "chatcmpl-8Ygj0WAGNhHBFjatPCefcPeNi12ct",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": { "content": "Hello World", "role": "assistant" }
    }
  ],
  "created": 1703230636,
  "model": "gpt-3.5-turbo",
  "object": "chat.completion",
  "system_fingerprint": null,
  "usage": { "completion_tokens": 2, "prompt_tokens": 12, "total_tokens": 14 },
  "_response_ms": 653.2679999999999
}
``` */}

## Next steps
Congratulations! You have integrated LLM proxy into your codebase! When you make any API call, you will see the LLM log on [the platform](https://platform.keywordsai.co/platform/).
<CardGroup cols={2}>
<Card title="Call 300+ LLMs" href="/features/generation/gateway">
</Card>
<Card title="Complete LLM observability" href="/features/monitoring/overview">
</Card>
<Card title="Prompt engineering" href="/get-started/prompt-engineering">
</Card>
</CardGroup>