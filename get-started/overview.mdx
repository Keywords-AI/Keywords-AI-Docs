---
title: 'What is Keywords AI?'
description: 'Keywords AI is a full-stack LLM engineering platform for developers and PMs.'
---

{/* Keywords AI makes it easy for developers to build LLM applications. With 2 lines of code, developers get a complete LLMOps platform that speeds up deploying & monitoring AI apps in production. */}

Keywords AI helps developers and PMs build reliable AI products 10x faster. In a shared workspace, product teams can **build**, **monitor**, and **improve** AI performance.
{/* Keywords AI is an LLM engineering platform where you can build, monitor, and optimize your LLM applications with ease. We provide a unified API to access 200+ best-in-class models, enabling you to connect to the best model for your task.  */}
{/* <img src="/images/poster.png" alt="Users Page data" /> */}

<iframe   
        width="640"
        height="360"
        src="https://www.youtube.com/embed/yR2JblPcgak?si=3o4SE_81QJoG-v7z" 
        title="YouTube video player" 
        frameborder="0" 
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" 
        allowfullscreen>
</iframe>


{/* ## What can I use Keywords AI for?
Developers use Keywords AI to:
- Access 200+ best-in-class models through our unified LLM API.
- Monitor LLM applications with detailed performance metrics and usage data.
- Test prompts across different models and compare their responses.
- Evaluate AI performance based on built-in or custom metrics. */}

There are 2 main challenges in building AI products

> **Getting reliable AI performance**
>
> Building enterprise-level AI products requires reliable LLM outputs. Teams must track performance and costs while ensuring outputs remain unbiased.

> **Collaboration in AI Development**
>
> AI product development requires collaboration among people with different expertise. A shared workspace enables team members to build and improve AI products together effectively.





## Getting started with Keywords AI

Keywords AI helps AI teams build reliable products faster through advanced observability, prompt engineering, and evaluation tools.

<CardGroup cols={2}>
  <Card title="I'm an AI startup founder"  href="/get-started/llm-inference">
     Build your AI product quickly with our LLM Proxy
  </Card>
  <Card title="I'm an AI engineer"  href="/get-started/async-logging">
  Monitor and optimize AI performance
    </Card>
    <Card title="I'm a product manager"  href="/get-started/evaluation">
   Collaborate with engineers on prompt engineering.
  </Card>
</CardGroup>

Select your role above to begin with the most relevant features for you.


{/* You can start using Keywords AI in 2 ways:
- [**LLM Proxy**](/get-started/llm-inference):
  - Leverage 200+ best-in-class models with a single API.
  - Compatible with OpenAI, Anthropic, LangChain, and other mainstream SDKs.
  - Guarantee your LLM applications's uptime with fallback models.
  - Enhance LLM rate limits and reliability with load balancing.
- [**Aysnc Logging**](/get-started/async-logging):
  - Integration time < 5 minutes.
  - 0 latency impact on your application.
  - Operates outside the critical path of your application.
  - Get complete observability immediately.

## Proxy Integrations
<CardGroup cols={3}>
<Card title="OpenAI SDK" icon="merge" color="#DA8FFF" href="/integration/development-frameworks/openai-sdk">
   Switch from OpenAI SDK to Keywords AI with 2 lines of code.
  </Card>
  <Card title="Anthropic SDK" icon="merge" color="#DA8FFF" href="/integration/development-frameworks/anthropic">
    Switch from Anthropic SDK to Keywords AI with 2 lines of code.
  </Card>
    <Card title="LangChain SDK" icon="merge" color="#DA8FFF" href="/integration/development-frameworks/langchain">
    Switch from LangChain SDK to Keywords AI with 2 lines of code.
  </Card>
      <Card title="Vercel SDK" icon="merge" color="#DA8FFF" href="/integration/development-frameworks/vercel">
    Switch from Vercel SDK to Keywords AI with 2 lines of code.
  </Card>
        <Card title="LlamaIndex SDK" icon="merge" color="#DA8FFF" href="/integration/development-frameworks/llama-index">
    Switch from Vercel SDK to Keywords AI with 2 lines of code.
  </Card>
</CardGroup> */}

{/* ## Unified LLM API
<CardGroup cols={2}>
  <Card title="Integrate 200+ LLMs" icon="arrows-split-up-and-left" color="#FFB340" href="/integration/supported-models">
    Connect to over 200 best-in-class models through a single, unified API.
  </Card>
  <Card title="Enable fallback models" icon="arrows-split-up-and-left" color="#FFB340" href="/features/generation/fallbacks">
    Guarantee uptime with fallback models
  </Card>
    <Card title="Load balancing" icon="arrows-split-up-and-left" color="#FFB340" href="/features/generation/load-balancing">
    Boost LLM rate limits and reliability.
  </Card>
  <Card title="Custom metadata" icon="arrows-split-up-and-left" color="#FFB340" href="/features/generation/metadata">
    Easily track and annotate your data with your custom metadata.
  </Card>
  <Card title="API keys management" icon="arrows-split-up-and-left" color="#FFB340" href="/features/generation/key-management">
       Centralize all API keys, enabling access control and user permissions.
  </Card>
  </CardGroup>

  ## LLM monitoring
  <CardGroup cols={2}>
  <Card title="Usage dashboard" icon="eyes" color="#66D4CF" href="/features/monitoring/analytics">
    A graphical view for monitoring your usage, performance, and cost.
  </Card>
  <Card title="Logs" icon="eyes" color="#66D4CF" href="/features/monitoring/logging">
    Debug, test, and improve LLM outputs with detailed metrics.
  </Card>
    <Card title="User analytics" icon="eyes" color="#66D4CF" href="/features/user/users-data">
    Insights into your users' behavior and usage.
  </Card>
    <Card title="Alerts" icon="eyes" color="#66D4CF" href="/features/monitoring/subscribe-alerts">
    Subscribe to the system status and get notified when an outage occurs.
  </Card>
  <Card title="Webhooks" icon="eyes" color="#66D4CF" href="/features/monitoring/webhooks">
    Get notified when a request is completed.
  </Card>
</CardGroup>

## Prompt testing
  <CardGroup cols={2}>
<Card title="LLM playground" icon="flask" color="#FF6482" href="/features/prompt/test&compare">
    Test the API with your prompts on different models and compare the results.
  </Card>
  <Card title="Prompt management" icon="flask" color="#FF6482" href="/features/prompt/prompt-management">
    Iterating and versioning prompts as a team.
  </Card>
</CardGroup>

## Evaluation & improvement
  <CardGroup cols={2}>
    <Card title="Evaluations" icon="medal" color="#5DE6FF" href="/features/evaluation/overview">
    Evaluate your AI performance based on built-in or custom metrics.
    </Card>
    <Card title="Datasets" icon="medal" color="#5DE6FF" href="/features/datasets">
    Create high-quality golden datasets for model fine-tuning.
    </Card>
</CardGroup>

## API reference
<CardGroup cols={2}>
  <Card title="Unified LLM API" icon="books" color="#73CB98" href="/api-endpoints/integration/chat-completions">
    The `/api/chat/completions` endpoint allows you to generate text based on text/images input.
  </Card>
    <Card title="Async logging" icon="books" color="#73CB98" href="/api-endpoints/integration/request-logging-endpoint">
    The `/api/request-logs/create/` endpoint allows you to log your requests and responses.
  </Card>
  <Card title="Models" icon="books" color="#73CB98" href="/api-endpoints/data-endpoints/models-endpoint">
    The `models` endpoint allows you to see all the models available on Keywords AI.
  </Card>
</CardGroup> */}

{/* You can start using Keywords AI in 2 ways:
- **API proxy**: Use our unified LLM API to build, monitor, and enhance your LLM applications with just 2 lines of code.
  - Guarantee your LLM applications's uptime with fallback models.
  - Enhance LLM rate limits and reliability with load balancing.
  - Leverage 200+ best-in-class models with a single API.
  - Provide access control and user permissions with API keys management.
- **Aysnc Logging**: Use our async logging API to monitor your custom model.
  - Integration time < 5 minutes.
  - 0 latency impact on your application.
  - Operates outside the critical path of your application.

[Get started with 2 lines of code](/get-started/guide) */}


{/* ## Integrations
<CardGroup cols={3}>
  <Card title="OpenAI" icon="link" href="/integration/development-frameworks/openai-sdk">
    Switch from OpenAI to Keywords AI with 2 lines of code.
  </Card>
    <Card title="Anthropic" icon="link" href="/integration/development-frameworks/anthropic">
    Switch from Anthropic to Keywords AI with 2 lines of code.
  </Card>
  <Card title="LangChain" icon="link" href="/integration/development-frameworks/langchain">
    Switch from LangChain to Keywords AI with 2 lines of code.
  </Card>
  <Card title="LlamaIndex" icon="link" href="/integration/development-frameworks/llama-index">
    Switch from LlamaIndex to Keywords AI with 2 lines of code.
  </Card>
  <Card title="Use own credentials" icon="link" href="/integration/own-api-keys">
  Bring your own keys to call LLMs
  </Card>
  <Card title="Custom model" icon="link" href="/get-started/fine-tuned-model">
  Use our async logging API to monitor your custom model
  </Card>
</CardGroup> */}

{/* ## Unified LLM API
The Keywords AI Unified LLM API offers you a streamlined and powerful solution to enhance your LLM applications:
- **Single API Access:** Connect to over 200 best-in-class models through a single, unified API.
- **API Keys Management:** Centralize all API keys, enabling access control and user permissions within your organization.
- **Fallback Models:** Enable fallback models to ensure maximum uptime and reliability for your applications.
- **Load Balancing:** Efficiently distribute your requests across multiple models and API deployments to optimize performance and resource utilization.

[Get started with 2 lines of code](/get-started/guide#unified-llm-api)

## LLM monitoring
With Keywords AI, you can monitor your LLM applications with ease.
- **Observability:** Gain insights into your LLM applications with detailed performance metrics and usage data.
- **User analytics:** Understand your users' activities to optimize your LLM applications.
- **Subscribe alerts:** Get notified when outages occur and receive alerts to take action immediately.

[Begin monitoring your LLM applications today!](/get-started/guide#llm-monitoring)

## Prompt testing
Leverage Keywords AI's prompt management and LLM playground to refine and test your prompts across different models, and compare their responses.
- **Build and Test Prompts:** Create, test, and refine prompts to optimize your LLM applications.
- **Send to Playground:** Test your prompts in the playground with a single click.
- **Try 200+ LLMs:** Experiment with over 200 top-tier LLMs in the playground.
- **One-Click Deployment:** Deploy your optimized prompts to production effortlessly.

[Access 200+ LLMs now!](/get-started/guide#prompt-testing)

## Evaluation & improvement
Evaluate your AI performance based on built-in or custom metrics and improve your LLM applications.
- Evaluate LLM performance with 10+ metrics.
- Customize metrics to suit your specific use case.
- Perform evaluations on production data or sample a percentage of your data.
- Utilize the best data to create high-quality golden datasets.

[Check out our evaluation features!](/get-started/guide#evaluation-and-improvement) */}

{/* ## User analytics
<CardGroup cols={2}>
  <Card title="User data" icon="link" href="/features/user/users-data">
    Insights into your users' behavior and usage.
  </Card>
    <Card title="User creation & update" icon="link" href="/features/user/user-creation">
    Insights into your users' behavior and usage.
  </Card>
</CardGroup> */}

{/* ## Platform features
<CardGroup cols={2}>
<Card title="LLM playground" icon="link" href="/features/prompt/test&compare">
    Test the API with your prompts on different models and compare the results.
  </Card>
  <Card title="Prompt management" icon="link" href="/features/prompt/prompt-management">
    Iterating and versioning prompts as a team.
  </Card>
    <Card title="Datasets" icon="link" href="/features/datasets">
    Iterating and versioning prompts as a team.
  </Card>
    <Card title="Evaluations" icon="link" href="/features/evaluation/overview">
    Evaluate your AI performance based on built-in or your own metrics.
</Card>
</CardGroup>


## API reference
<CardGroup cols={2}>
  <Card title="LLM inference" icon="link" href="/api-endpoints/proxy-endpoints/chat-completions">
    The `/api/chat/completions` endpoint allows you to generate text based on text/images input.
  </Card>
    <Card title="Async logging" icon="link" href="/api-endpoints/async-endpoints/request-logging-endpoint.mdx">
    The `/api/request-logs/create/` endpoint allows you to log your requests and responses.
  </Card>
  <Card title="Models" icon="link" href="/api-endpoints/data-endpoints/models-endpoints">
    The `models` endpoint allows you to see all the models available on Keywords AI.
  </Card>
</CardGroup> */}
