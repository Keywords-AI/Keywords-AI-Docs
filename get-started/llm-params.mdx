---
title: LLM Parameters
description: 'Definitions and explanations for parameters for LLM router API'
---

## Logprobs

The logprobs parameter in LLM (Language Model) generation refers to the logarithm of the predicted probabilities assigned by the model to each possible next word or token in a generated sequence. This parameter allows users to control the level of uncertainty in the generated text by adjusting the temperature value. Higher temperature values result in more diverse and creative output, as the model assigns higher probabilities to a wider range of words. Conversely, lower temperature values lead to more focused and deterministic output, as the model assigns higher probabilities to highly likely words. By analyzing the logprobs, users can gain insights into the model's confidence and make informed choices about the generated text.
