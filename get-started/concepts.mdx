---
title: Key Concepts and Explanations
description: 'Explanations for basic concepts/terminologies'
---

## Large Language Models (LLMs)

LLMs are advanced AI models designed to understand, generate, and manipulate human language. They are trained on extensive datasets, enabling them to perform a wide range of text-based tasks with high accuracy.

## Tokens

In the context of LLMs, tokens refer to the smallest units of text processed by the model. A token can be as small as a single character or as large as a word. As an approximation, 1000 tokens are roughly equivalent to 750 words. For instance, this definition of a token (not including this sentence) is around 43 tokens.

## LLM Evaluation Frameworks

The Keywords AI API employs sophisticated evaluation frameworks to assess LLMs. These frameworks analyze model performance across various dimensions, such as accuracy, response time, and contextual relevance. For example, a model may be evaluated based on its ability to generate coherent text, translate languages accurately, or understand user intent in conversational AI applications. By continuously monitoring and evaluating LLMs, the API ensures that only the most effective models are utilized for user requests.