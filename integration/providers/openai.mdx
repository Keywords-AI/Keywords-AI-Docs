---
title: "Add API keys"
---

<Note> This section is only for **Keywords AI LLM proxy** user.</Note>

To use Keywords AI LLM proxy, you need to add your own credentials to call models from each provider. Here's how you can add your OpenAI credentials on Keywords AI.

## Add API keys from the UI

<Steps>
<Step title="Go to the Credentials page">
The [Credentials page](https://platform.keywordsai.co/platform/api/credentials) allows you to add your own credentials for each provider. Currently, over 20+ providers are supported.
<img width="600"  src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/Integrations/api_keys/openai_1.png" alt="Keywords AI Credentials Page"/>
</Step>
<Step title="Add your OpenAI API key.">

<img width="600"  src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/Integrations/api_keys/openai_2.png" alt="Keywords AI Credentials Page"/>
</Step>
<Step title="Add more OpenAI API keys.">
We support adding multiple OpenAI API keys. You can add as many as you want. In the field of `Load balancing weight`, you can set the weight of the API key. This is used to distribute the load between the API keys.
</Step>
</Steps>

## Add API keys in code
Add `customer_credentials` parameter in your [request body](/api-endpoints/integration/chat-completions) to use your own OpenAI credits.

```json
{
  // Rest of the request body
  "customer_credentials": {
    "openai": {
      "api_key": "YOUR_OPENAI_API_KEY",
    }
  }
}
```
### Load balancing between API keys
You can add different API keys in the `customer_credentials` field and specify the weight for each deployment. Check out our [Load balancing](/features/generation/load-balancing#load-balancing-between-deployments) documentation for more details.
```json
{
  "customer_credentials": [
    {
        "credentials": {
            "openai": {
                "api_key": "YOUR_OPENAI_API_KEY",
            }
        },
        "weight": 1.0 // The weight of the deployment
    },
    {
        "credentials": {
            "openai": {
                "api_key": "YOUR_OPENAI_API_KEY", // Another deployment
            }
        },
        "weight": 1.0 // The weight of the deployment
    },
  ],
}
```
## Override credentials for a particular model. (Optional)
One-off credential overrides. Instead of using what is uploaded for each provider, this targets credentials for individual models. In the example below, we are overriding the API key for the `gpt-4o` model.
```json
{
  // Rest of the request body
  "customer_credentials": {
    "openai": {
      "api_key": "YOUR_OPENAI_API_KEY",
    }
  },
  "credential_override": {
    "gpt-4o":{ // override for a specific model.
      "api_key": "YOUR_ANOTHER_OPENAI_API_KEY",
    }
  }
}
```

## Full request example
<Accordion title="Example">
<CodeGroup>
```python openai_example.py
from openai import OpenAI

client = OpenAI(
    base_url="https://api.keywordsai.co/api/",
    api_key="YOUR_KEYWORDSAI_API_KEY",
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role":"user", "content":"Tell me a long story"}],
    extra_body={
      "customer_credentials": {
          "openai": {"api_key": "YOUR_OPENAI_API_KEY",}
       }
    }
)
```
```python api_example.py
import requests
def demo_call(input, 
              model="gpt-4o",
              token="YOUR_KEYWORDS_AI_API_KEY"
              ):
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {token}',
    }

    data = {
        'model': model,
        'messages': [{'role': 'user', 'content': input}],
        'customer_credentials': {
            'openai': {"api_key": "YOUR_OPENAI_API_KEY",}
        }
    }

    response = requests.post('https://api.keywordsai.co/api/chat/completions', headers=headers, json=data)
    return response

messages = "Say 'Hello World'"
print(demo_call(messages).json())
```
</CodeGroup>
</Accordion>
